{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network(RNN)\n",
    "\n",
    "* Hidden states.\n",
    "* GRU is faster and more efficient than LSTM, but it may not capture long-term dependencies as well as LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues with RNN-\n",
    "* exploding gradients\n",
    "* Vanishing gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications of Recurrent Neural Network\n",
    "1. Language Modelling and Generating Text\n",
    "2. Speech Recognition\n",
    "3. Machine Translation\n",
    "4. Image Recognition, Face detection\n",
    "5. Time series Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "text = \"This is GeeksforGeeks a software training institute\"\n",
    "chars = sorted(list(set(text)))\n",
    "char_to_index = {char: i for i, char in enumerate(chars)}\n",
    "index_to_char = {i: char for i, char in enumerate(chars)}\n",
    "\n",
    "seq_length = 3\n",
    "sequences = []\n",
    "labels = []\n",
    " \n",
    "for i in range(len(text) - seq_length):\n",
    "    seq = text[i:i+seq_length]\n",
    "    label = text[i+seq_length]\n",
    "    sequences.append([char_to_index[char] for char in seq])\n",
    "    labels.append(char_to_index[label])\n",
    "\n",
    "X = np.array(sequences)\n",
    "y = np.array(labels)\n",
    " \n",
    "X_one_hot = tf.one_hot(X, len(chars))\n",
    "y_one_hot = tf.one_hot(y, len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(50, input_shape=(seq_length, len(chars)), activation='relu'))\n",
    "model.add(Dense(len(chars), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_one_hot, y_one_hot, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_seq = \"This is G\"\n",
    "generated_text = start_seq\n",
    " \n",
    "for i in range(50):\n",
    "    x = np.array([[char_to_index[char] for char in generated_text[-seq_length:]]])\n",
    "    x_one_hot = tf.one_hot(x, len(chars))\n",
    "    prediction = model.predict(x_one_hot)\n",
    "    next_index = np.argmax(prediction)\n",
    "    next_char = index_to_char[next_index]\n",
    "    generated_text += next_char\n",
    " \n",
    "print(\"Generated Text:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: importing libraries  \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "#step 3: creATING THE MODEL\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_d, hidden_d, layer_d, output_d):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_d\n",
    "        self.layer_dim = layer_d\n",
    "\n",
    "        # LSTM model \n",
    "        self.lstm = nn.LSTM(input_d, \n",
    "                            hidden_d, # The number of features in the hidden state\n",
    "                            layer_d, # Number of LSTm units\n",
    "                            batch_first=True) \n",
    "\n",
    "        self.fc = nn.Linear(hidden_d, output_d)\n",
    "\n",
    "    def forward(self, x):\n",
    "    \n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out\n",
    "    \n",
    "input_dim = 30\n",
    "hidden_dim = 120\n",
    "output_dim = 15\n",
    "layer_dim = 1\n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "#step 4: calculating cross entropy loss\n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "#step 5: optimizer \n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.0804e-01,  1.0536e-01,  8.4410e-02,  3.2601e-01, -2.4294e-01,\n",
       "          -5.2516e-02, -3.3121e-01,  1.1482e-01, -8.5209e-02,  3.0737e-01,\n",
       "          -1.1983e-01, -4.1634e-01,  2.9831e-01, -5.1683e-02, -1.5111e-01,\n",
       "           9.3403e-03,  9.7062e-02, -1.8577e-01, -4.7152e-01,  4.7980e-01],\n",
       "         [-2.0429e-01,  2.5425e-01,  2.7489e-01,  6.8165e-03, -8.3660e-02,\n",
       "          -1.9244e-01, -1.1154e-01, -2.5222e-01,  2.4354e-01, -4.8548e-02,\n",
       "          -3.2129e-01, -4.1662e-01, -2.4041e-01,  1.4034e-01, -2.1557e-01,\n",
       "           2.2824e-02,  2.0095e-01, -1.2763e-01,  6.3286e-02,  8.7747e-02],\n",
       "         [-2.7469e-01,  6.3348e-02, -1.7253e-01, -3.1963e-01,  1.5097e-02,\n",
       "           2.7225e-01, -5.4149e-03, -1.3163e-01,  9.6795e-03,  2.6569e-02,\n",
       "           1.8100e-01, -1.3790e-01,  6.9847e-02,  2.8704e-02, -1.1013e-01,\n",
       "           2.5623e-01,  1.7752e-01, -9.0763e-02,  3.1469e-01,  1.1455e-01]],\n",
       "\n",
       "        [[-1.5764e-01,  4.5582e-02,  6.3595e-02,  1.7890e-01, -5.1543e-02,\n",
       "          -4.4381e-02, -2.1377e-01,  4.7981e-02,  6.3566e-02,  2.2221e-01,\n",
       "           9.3426e-03, -1.7814e-01,  3.5147e-02, -3.0865e-02, -1.6899e-01,\n",
       "          -4.7694e-03,  9.7501e-03,  9.5294e-03, -2.1785e-01,  1.4449e-01],\n",
       "         [-9.5927e-02,  1.0621e-01,  1.5551e-01, -3.5745e-02, -1.7809e-02,\n",
       "          -6.5287e-02, -9.4105e-02, -2.4726e-01,  9.2965e-02, -1.9812e-02,\n",
       "          -6.1938e-02, -1.9263e-01, -1.8043e-01,  7.6516e-02, -2.2996e-01,\n",
       "           6.7783e-02,  1.5986e-01, -1.9203e-01,  1.1883e-01,  1.7878e-02],\n",
       "         [-1.3492e-01,  1.0027e-01, -8.4356e-02, -8.8860e-02,  6.4884e-02,\n",
       "           1.5903e-01, -5.7994e-02, -1.8240e-01,  3.4381e-03, -6.8900e-03,\n",
       "           8.4011e-02, -5.8941e-02,  5.2105e-03,  5.1864e-03, -1.8274e-01,\n",
       "           9.4014e-02,  1.3564e-01, -9.8712e-02,  2.2905e-01,  1.4538e-01]],\n",
       "\n",
       "        [[ 1.4919e-02,  2.5234e-02,  2.2187e-02,  3.9947e-02,  3.7179e-02,\n",
       "          -5.7723e-02, -1.4123e-01, -3.1209e-02,  9.5550e-02,  1.1468e-01,\n",
       "           2.5097e-02, -9.6143e-02, -2.3565e-02, -5.4263e-03, -2.0482e-01,\n",
       "          -3.3194e-02,  4.5170e-03,  4.0575e-02, -5.6664e-02,  8.8814e-02],\n",
       "         [ 1.6012e-02,  8.9280e-02,  9.4181e-02, -3.9828e-02,  2.3097e-02,\n",
       "          -2.7560e-02, -7.3646e-02, -2.0338e-01,  7.2978e-02, -6.9398e-03,\n",
       "          -3.5755e-03, -1.1009e-01, -8.9496e-02,  3.7447e-02, -2.2919e-01,\n",
       "           3.1338e-02,  8.3851e-02, -1.5666e-01,  1.4904e-01,  5.2413e-03],\n",
       "         [ 4.3512e-02,  8.2889e-02,  2.4318e-03, -6.5484e-02,  8.3405e-02,\n",
       "           8.0325e-02, -8.8001e-02, -1.5759e-01,  9.2965e-03, -3.1094e-02,\n",
       "           5.5531e-02, -5.3824e-02, -2.4316e-02, -1.5203e-03, -1.9743e-01,\n",
       "           4.9693e-02,  1.0525e-01, -1.1091e-01,  2.2814e-01,  9.8271e-02]],\n",
       "\n",
       "        [[ 9.3018e-02,  1.3819e-02,  1.9824e-02, -2.1875e-02,  8.6827e-02,\n",
       "          -6.7113e-02, -1.1335e-01, -7.1659e-02,  8.9142e-02,  4.6975e-02,\n",
       "           1.4412e-02, -8.3526e-02, -3.2169e-02, -1.7316e-02, -2.2176e-01,\n",
       "          -3.6996e-02,  4.3496e-03,  1.6509e-02,  3.4880e-02,  7.2194e-02],\n",
       "         [ 7.3045e-02,  4.7470e-02,  6.1451e-02, -4.0499e-02,  4.1726e-02,\n",
       "          -1.4136e-02, -6.9241e-02, -1.7016e-01,  6.3078e-02, -1.4453e-02,\n",
       "           6.2520e-03, -8.6262e-02, -4.7307e-02, -1.3775e-02, -2.1560e-01,\n",
       "           1.1591e-02,  4.5510e-02, -1.2278e-01,  1.6550e-01,  2.3094e-02],\n",
       "         [ 1.2465e-01,  7.2604e-02,  4.3845e-02, -4.3597e-02,  9.3715e-02,\n",
       "           4.5607e-02, -7.9016e-02, -1.4161e-01,  2.0625e-02, -3.8914e-02,\n",
       "           4.8722e-02, -6.6245e-02, -2.1842e-02,  7.3319e-03, -2.0597e-01,\n",
       "           3.0389e-02,  8.7520e-02, -1.0043e-01,  2.3468e-01,  6.4061e-02]],\n",
       "\n",
       "        [[ 1.2388e-01, -2.1124e-03,  2.5648e-02, -3.3550e-02,  9.5865e-02,\n",
       "          -4.6065e-02, -9.4604e-02, -9.9275e-02,  7.7147e-02, -1.4272e-02,\n",
       "           4.8755e-03, -7.4115e-02, -1.0476e-02, -2.2441e-02, -2.2106e-01,\n",
       "          -4.7020e-02, -3.0597e-03, -4.4115e-03,  1.0372e-01,  4.3059e-02],\n",
       "         [ 1.1974e-01,  1.7498e-02,  4.8037e-02, -4.1882e-02,  5.1838e-02,\n",
       "          -1.8866e-02, -7.7474e-02, -1.5159e-01,  4.6050e-02, -3.2101e-02,\n",
       "           6.5328e-03, -7.6373e-02, -4.2492e-02, -3.4745e-02, -2.2059e-01,\n",
       "          -2.8328e-02,  5.6188e-02, -1.1635e-01,  1.8317e-01,  3.6375e-02],\n",
       "         [ 1.6825e-01,  3.8766e-02,  5.2074e-02, -4.3483e-02,  1.3225e-01,\n",
       "           4.9460e-03, -7.7087e-02, -1.2658e-01,  1.2666e-02, -5.1689e-02,\n",
       "           1.0974e-02, -4.4537e-02,  3.5391e-04,  2.3424e-03, -2.0636e-01,\n",
       "          -4.9513e-03,  6.0654e-02, -8.3053e-02,  2.1560e-01,  4.3607e-02]]],\n",
       "       grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.LSTM(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "c0 = torch.randn(2, 3, 20)\n",
    "output, (hn, cn) = rnn(input, (h0, c0))\n",
    "\n",
    "print(output.size())\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 20])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM using tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, save_model, load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 10, 100)           48400     \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 10, 40)            22560     \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 50)                18200     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 408       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89577 (349.91 KB)\n",
      "Trainable params: 89577 (349.91 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_features = 20                        \n",
    "\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(InputLayer((10,n_features)))\n",
    "model1.add(LSTM(units=100, return_sequences = True))     \n",
    "model1.add(LSTM(40, return_sequences = True))\n",
    "model1.add(LSTM(50))\n",
    "model1.add(Dense(8, activation = 'relu'))\n",
    "model1.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = 'val_loss', patience = 2)\n",
    "\n",
    "model1.compile(loss = MeanSquaredError(), \n",
    "               optimizer = Adam(learning_rate = 0.0001), \n",
    "               metrics = RootMeanSquaredError())\n",
    "\n",
    "model1.fit(X_train, y_train, \n",
    "           validation_data = (X_val, y_val), \n",
    "           epochs = 50, \n",
    "           callbacks = [early_stop])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
