{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (Non linear problems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Every module in PyTorch subclasses the nn.Module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -q tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary library\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn # torch.nn namespace provides all the building blocks you need to build your own neural network.\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n",
      "tensor([[[0.0504, 0.8947, 0.2288,  ..., 0.8567, 0.3168, 0.8990],\n",
      "         [0.8838, 0.8528, 0.9799,  ..., 0.1934, 0.5887, 0.1273],\n",
      "         [0.5529, 0.7707, 0.2857,  ..., 0.5629, 0.0726, 0.4640],\n",
      "         ...,\n",
      "         [0.5918, 0.5450, 0.4096,  ..., 0.6315, 0.7036, 0.3030],\n",
      "         [0.7919, 0.1907, 0.5372,  ..., 0.2951, 0.9086, 0.3339],\n",
      "         [0.8247, 0.3221, 0.6539,  ..., 0.6823, 0.2273, 0.1844]],\n",
      "\n",
      "        [[0.8727, 0.3278, 0.0930,  ..., 0.0768, 0.9419, 0.7781],\n",
      "         [0.2341, 0.2435, 0.1499,  ..., 0.7503, 0.6852, 0.4001],\n",
      "         [0.4934, 0.4903, 0.0756,  ..., 0.0104, 0.3208, 0.1865],\n",
      "         ...,\n",
      "         [0.6090, 0.5347, 0.0583,  ..., 0.4486, 0.1968, 0.6290],\n",
      "         [0.5957, 0.8413, 0.8027,  ..., 0.9878, 0.1033, 0.7163],\n",
      "         [0.2771, 0.7055, 0.2958,  ..., 0.5621, 0.3019, 0.5191]],\n",
      "\n",
      "        [[0.6832, 0.3939, 0.3172,  ..., 0.3044, 0.2071, 0.1793],\n",
      "         [0.8646, 0.4800, 0.9653,  ..., 0.6829, 0.2499, 0.2173],\n",
      "         [0.1331, 0.0341, 0.5350,  ..., 0.2007, 0.4406, 0.0680],\n",
      "         ...,\n",
      "         [0.8544, 0.7690, 0.3782,  ..., 0.8183, 0.4060, 0.9403],\n",
      "         [0.9266, 0.4787, 0.5752,  ..., 0.6954, 0.8154, 0.1687],\n",
      "         [0.1435, 0.9718, 0.2925,  ..., 0.9514, 0.7134, 0.9562]]])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())\n",
    "print(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n",
      "tensor([[0.0504, 0.8947, 0.2288,  ..., 0.6823, 0.2273, 0.1844],\n",
      "        [0.8727, 0.3278, 0.0930,  ..., 0.5621, 0.3019, 0.5191],\n",
      "        [0.6832, 0.3939, 0.3172,  ..., 0.9514, 0.7134, 0.9562]])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())\n",
    "print(flat_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n",
      "tensor([[ 0.2861, -0.3594,  0.5275, -0.4018, -0.1297,  0.1118, -0.0690, -0.2954,\n",
      "          0.5146, -0.2720,  0.3401, -0.4383, -0.1011,  0.3031,  0.2028,  0.2604,\n",
      "          0.1059, -0.4668,  0.5694, -0.4137],\n",
      "        [ 0.1466,  0.2805,  0.7327, -0.2291,  0.1350,  0.3265,  0.1327, -0.6191,\n",
      "          0.3225, -0.1646,  0.3650, -0.2924, -0.2761,  0.2765,  0.0956,  0.3204,\n",
      "          0.0273,  0.0031,  0.2421, -0.2222],\n",
      "        [ 0.1227,  0.1003,  0.3599, -0.5632,  0.0815,  0.1213, -0.3312, -0.4519,\n",
      "          0.7450,  0.3061,  0.4536, -0.4046, -0.1204,  0.1463,  0.4700, -0.0416,\n",
      "         -0.0021, -0.3618,  0.5015, -0.3423]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Took all input 28*28 and multiplied with weights, then applied summation, linear transformation, output [-1, 1]\n",
    "\n",
    "layer1 = nn.Linear(in_features=28*28, out_features=20) # Applies a linear transformation to the incoming data: :math:`y = xA^T + b`\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())\n",
    "print(hidden1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After ReLU: tensor([[0.2861, 0.0000, 0.5275, 0.0000, 0.0000, 0.1118, 0.0000, 0.0000, 0.5146,\n",
      "         0.0000, 0.3401, 0.0000, 0.0000, 0.3031, 0.2028, 0.2604, 0.1059, 0.0000,\n",
      "         0.5694, 0.0000],\n",
      "        [0.1466, 0.2805, 0.7327, 0.0000, 0.1350, 0.3265, 0.1327, 0.0000, 0.3225,\n",
      "         0.0000, 0.3650, 0.0000, 0.0000, 0.2765, 0.0956, 0.3204, 0.0273, 0.0031,\n",
      "         0.2421, 0.0000],\n",
      "        [0.1227, 0.1003, 0.3599, 0.0000, 0.0815, 0.1213, 0.0000, 0.0000, 0.7450,\n",
      "         0.3061, 0.4536, 0.0000, 0.0000, 0.1463, 0.4700, 0.0000, 0.0000, 0.0000,\n",
      "         0.5015, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## They are applied after linear transformations to introduce nonlinearity\n",
    "\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n",
      "tensor([[0.0555, 0.0417, 0.0707, 0.0417, 0.0417, 0.0466, 0.0417, 0.0417, 0.0698,\n",
      "         0.0417, 0.0586, 0.0417, 0.0417, 0.0565, 0.0511, 0.0541, 0.0464, 0.0417,\n",
      "         0.0737, 0.0417],\n",
      "        [0.0479, 0.0548, 0.0861, 0.0414, 0.0474, 0.0574, 0.0473, 0.0414, 0.0572,\n",
      "         0.0414, 0.0596, 0.0414, 0.0414, 0.0546, 0.0455, 0.0570, 0.0425, 0.0415,\n",
      "         0.0527, 0.0414],\n",
      "        [0.0465, 0.0454, 0.0589, 0.0411, 0.0446, 0.0464, 0.0411, 0.0411, 0.0866,\n",
      "         0.0558, 0.0647, 0.0411, 0.0411, 0.0476, 0.0658, 0.0411, 0.0411, 0.0411,\n",
      "         0.0679, 0.0411]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([18,  2,  8])\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1) # gets the output probability\n",
    "pred_probab = softmax(hidden1)\n",
    "output = pred_probab.argmax(1)\n",
    "print(pred_probab.size())\n",
    "print(pred_probab)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other available layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden2 = nn.Conv2d(in_channels=16, # Number of channels in the input image\n",
    "                    out_channels=33, \n",
    "                    kernel_size=3, # Size of the convolving kernel\n",
    "                    stride=(2,1),\n",
    "                    padding=(4,2),\n",
    "                    dilation=(3,1), #Spacing between kernel elements.\n",
    "                    groups=None,\n",
    "                    bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 33, 26, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Conv2d(16, 33, kernel_size=(3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (H X W X C X B)\n",
    "\n",
    "# With square kernels and equal stride\n",
    "m = nn.Conv2d(16, 33, 3, stride=2) # o/p = (50-3)/2 +1 and (100-3)/2 +1\n",
    "\n",
    "# # non-square kernels and unequal stride and with padding\n",
    "m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2)) # o/p = (50+4+4-3)/2 +1 and (100+2+2-5)/1 +1\n",
    "# # non-square kernels and unequal stride and with padding and dilation\n",
    "m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
    "input = torch.randn(20, 16, 50, 100)\n",
    "output = m(input)\n",
    "print(output.size())\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.6838, -1.9966,  0.1360, -1.0349],\n",
       "          [ 0.8146, -2.3455,  0.8414, -1.6261],\n",
       "          [ 1.9926, -1.0358,  0.5337,  2.6652],\n",
       "          [-0.3238, -1.5145, -1.8557,  2.0575]],\n",
       "\n",
       "         [[ 0.0000, -0.0000, -0.0000, -0.0000],\n",
       "          [-0.0000, -0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000, -0.0000],\n",
       "          [ 0.0000, -0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[-0.0000,  0.0000,  0.0000, -0.0000],\n",
       "          [-0.0000,  0.0000, -0.0000,  0.0000],\n",
       "          [-0.0000,  0.0000, -0.0000, -0.0000],\n",
       "          [ 0.0000, -0.0000, -0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000, -0.0000,  0.0000, -0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000, -0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000, -0.0000, -0.0000,  0.0000]],\n",
       "\n",
       "         [[-0.0000,  0.0000, -0.0000,  0.0000],\n",
       "          [-0.0000, -0.0000, -0.0000, -0.0000],\n",
       "          [ 0.0000, -0.0000, -0.0000, -0.0000],\n",
       "          [-0.0000, -0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[-0.0000,  0.0000,  0.0000, -0.0000],\n",
       "          [-0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [-0.0000, -0.0000,  0.0000, -0.0000],\n",
       "          [-0.0000, -0.0000, -0.0000, -0.0000]]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Randomly zero out entire channels.\n",
    "\n",
    "m = nn.Dropout2d(p=0.5)\n",
    "input = torch.randn(2, 3, 4, 4)\n",
    "output = m(input)\n",
    "print(output.size())\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3, 3])\n",
      "tensor([[[[-2.1127, -0.0117, -0.9995, -0.7540],\n",
      "          [-1.6996,  0.1008, -1.8554,  0.4864],\n",
      "          [-1.2076,  0.5735, -1.3745,  1.0918],\n",
      "          [-1.3275, -2.2212,  0.0363,  0.3398]],\n",
      "\n",
      "         [[-1.1324, -1.0173,  0.7720, -1.0675],\n",
      "          [-0.4832,  1.3978,  0.4220, -0.9486],\n",
      "          [ 1.6168, -0.4436,  2.4575, -0.5579],\n",
      "          [-1.7259, -0.5059,  0.7828, -1.2560]],\n",
      "\n",
      "         [[ 1.2353, -1.3704, -0.8890,  0.1896],\n",
      "          [-0.8747, -0.6719, -0.5197,  0.5169],\n",
      "          [ 0.3571,  1.5120, -0.3358, -0.1510],\n",
      "          [-0.7454,  0.5255, -0.0294,  0.2510]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6875,  0.9067,  0.9233,  0.0235],\n",
      "          [ 0.2635,  0.8541,  1.2604, -0.6985],\n",
      "          [ 0.2171,  0.8380, -0.0724, -1.6606],\n",
      "          [ 2.0614,  0.1099, -0.2883, -0.5975]],\n",
      "\n",
      "         [[ 0.1161,  0.8428,  0.6648, -0.0188],\n",
      "          [-0.6637,  0.5589,  0.0941, -0.3291],\n",
      "          [ 0.4265,  0.4298, -1.4245, -0.1953],\n",
      "          [ 0.1856,  1.1143, -0.7100, -0.9153]],\n",
      "\n",
      "         [[-0.2793,  1.3125,  0.1996, -0.8110],\n",
      "          [ 0.1727, -0.8307,  1.7016, -0.8046],\n",
      "          [-0.9376,  0.9871, -2.2637, -0.5632],\n",
      "          [ 2.0251, -1.5049,  0.1104, -0.5201]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.9308, -0.6915, -0.7806],\n",
       "          [-0.5582, -0.6389, -0.4129],\n",
       "          [-1.0457, -0.7465,  0.0234]],\n",
       "\n",
       "         [[-0.3088,  0.3936, -0.2055],\n",
       "          [ 0.5219,  0.9584,  0.3432],\n",
       "          [-0.2646,  0.5727,  0.3566]],\n",
       "\n",
       "         [[-0.4204, -0.8627, -0.1755],\n",
       "          [ 0.0806, -0.0038, -0.1224],\n",
       "          [ 0.4123,  0.4181, -0.0663]]],\n",
       "\n",
       "\n",
       "        [[[ 0.6779,  0.9861,  0.3772],\n",
       "          [ 0.5432,  0.7200, -0.2928],\n",
       "          [ 0.8066,  0.1468, -0.6547]],\n",
       "\n",
       "         [[ 0.2135,  0.5401,  0.1028],\n",
       "          [ 0.1879, -0.0855, -0.4637],\n",
       "          [ 0.5390, -0.1476, -0.8113]],\n",
       "\n",
       "         [[ 0.0938,  0.5958,  0.0714],\n",
       "          [-0.1521, -0.1014, -0.4825],\n",
       "          [ 0.1424, -0.6678, -0.8092]]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.AvgPool2d(kernel_size=(2,2), stride=1, padding=0) # default stride = kernel\n",
    "input = torch.randn(2, 3, 4, 4)\n",
    "output = m(input)\n",
    "print(output.size())\n",
    "print(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 5.4101e-01, -3.7756e-01, -3.0646e-01,  ...,  7.2783e-02,\n",
      "           -1.2965e+00, -1.8411e-01],\n",
      "          [ 9.4833e-01,  5.9965e-01,  5.7454e-01,  ..., -9.9109e-01,\n",
      "            4.3715e-01,  5.1081e-01],\n",
      "          [-5.0062e-01, -7.2004e-01, -4.2925e-01,  ...,  2.1094e-01,\n",
      "            4.9922e-01,  3.5702e-01],\n",
      "          ...,\n",
      "          [-1.1852e+00,  7.2664e-01, -5.2805e-01,  ...,  7.4223e-03,\n",
      "            6.9306e-01, -1.2317e+00],\n",
      "          [-1.0776e+00, -6.3344e-01, -5.4436e-01,  ...,  1.5077e-01,\n",
      "            2.4860e+00, -3.9882e-01],\n",
      "          [ 9.8535e-01,  6.1906e-01,  1.2447e+00,  ...,  1.7745e+00,\n",
      "           -1.2297e+00, -9.5257e-01]],\n",
      "\n",
      "         [[-1.8146e+00, -2.9511e-01,  1.2121e+00,  ...,  9.0286e-01,\n",
      "            7.9889e-01, -3.1636e-01],\n",
      "          [ 1.3659e+00, -1.2297e+00, -7.8911e-01,  ...,  9.3384e-02,\n",
      "           -4.1785e-01, -7.9154e-02],\n",
      "          [ 1.9059e+00, -5.1964e-01,  3.2222e-01,  ..., -5.7145e-01,\n",
      "            1.1025e+00,  1.4887e+00],\n",
      "          ...,\n",
      "          [-1.5507e+00,  2.0689e+00, -4.4387e-02,  ...,  2.4787e-02,\n",
      "           -7.4537e-01, -8.5166e-01],\n",
      "          [-1.2349e-01,  2.2189e-01, -1.2631e+00,  ..., -3.5486e-01,\n",
      "            2.6939e-01,  1.7589e+00],\n",
      "          [-5.4819e-01,  6.8698e-01, -3.7240e-01,  ..., -8.7787e-02,\n",
      "           -1.1722e+00, -2.5535e-01]],\n",
      "\n",
      "         [[ 6.0206e-01,  1.4601e+00, -1.7188e+00,  ..., -1.0708e+00,\n",
      "           -3.2232e-02,  7.3511e-01],\n",
      "          [ 1.5247e+00,  2.0498e-01,  1.7308e-02,  ...,  5.4504e-01,\n",
      "            2.3043e-01,  1.7798e-01],\n",
      "          [-3.0701e-01, -8.5977e-02, -5.5295e-01,  ...,  1.1801e+00,\n",
      "           -7.4872e-01,  4.3187e-01],\n",
      "          ...,\n",
      "          [ 1.6975e+00, -1.1873e+00,  4.2048e-01,  ..., -3.3524e-01,\n",
      "            4.8371e-01,  2.0993e+00],\n",
      "          [-2.2604e-01, -1.2124e-01, -4.7440e-01,  ...,  7.0183e-01,\n",
      "            2.3919e-01, -1.5730e+00],\n",
      "          [-1.3640e-01, -2.1726e+00,  3.8001e-01,  ..., -3.8633e-01,\n",
      "            1.1830e+00, -8.4003e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.3525e-01,  1.2983e-01,  2.0854e-01,  ..., -1.3991e+00,\n",
      "           -3.2349e-01,  9.2541e-01],\n",
      "          [ 1.2562e-01,  2.3928e-01, -1.3112e+00,  ..., -4.0206e-01,\n",
      "           -8.0572e-01, -2.0515e-02],\n",
      "          [-7.0447e-02,  3.2620e-01, -8.4020e-01,  ...,  3.8911e-01,\n",
      "            5.8579e-01, -5.6664e-01],\n",
      "          ...,\n",
      "          [ 1.5319e+00,  1.1339e+00,  1.6716e+00,  ...,  5.0516e-01,\n",
      "            6.0527e-02, -2.0215e+00],\n",
      "          [-1.0933e+00,  4.5612e-01,  9.4858e-01,  ...,  1.6491e-01,\n",
      "            2.1448e+00, -3.0287e-01],\n",
      "          [-4.9354e-01,  5.7844e-02,  1.0782e+00,  ...,  6.2514e-02,\n",
      "            1.8872e+00, -1.5516e+00]],\n",
      "\n",
      "         [[-1.1470e+00,  4.6556e-02, -8.6892e-01,  ..., -1.1958e+00,\n",
      "           -3.0568e-02, -1.9161e-05],\n",
      "          [ 4.6281e-02,  1.7154e+00, -5.1936e-01,  ..., -2.0591e+00,\n",
      "           -1.4003e+00, -1.4691e-01],\n",
      "          [ 7.6783e-01, -3.3982e-01,  1.1664e-01,  ...,  3.7451e-01,\n",
      "           -7.2712e-01,  1.1274e+00],\n",
      "          ...,\n",
      "          [-3.9738e-01,  2.3097e+00, -7.1517e-01,  ...,  9.5017e-01,\n",
      "            1.6650e+00,  6.8550e-01],\n",
      "          [ 1.4970e+00, -1.7255e-01,  9.4426e-01,  ..., -1.0910e+00,\n",
      "            6.6393e-01, -1.0294e+00],\n",
      "          [ 6.2184e-02,  6.5948e-01, -9.4140e-01,  ...,  9.4735e-01,\n",
      "           -1.5813e-01,  4.6285e-01]],\n",
      "\n",
      "         [[ 3.9707e-01, -4.8768e-02, -1.5252e-01,  ..., -1.2774e+00,\n",
      "           -4.5043e-01,  6.0127e-01],\n",
      "          [ 1.1788e+00, -6.7774e-01,  7.5838e-01,  ..., -1.3341e-01,\n",
      "           -5.3450e-01, -7.8605e-01],\n",
      "          [-3.2023e+00,  7.1976e-01, -5.4222e-01,  ...,  1.3901e-01,\n",
      "            8.7231e-01,  1.8783e+00],\n",
      "          ...,\n",
      "          [-1.1246e+00,  3.9310e-01, -1.7344e-01,  ...,  1.6930e+00,\n",
      "           -1.1517e-01, -4.7081e-01],\n",
      "          [-1.1745e+00, -6.7825e-01, -3.7608e-01,  ...,  9.0235e-01,\n",
      "            4.0109e-01,  1.2009e-01],\n",
      "          [ 2.2441e-01,  1.8611e+00, -1.3913e+00,  ..., -8.2317e-01,\n",
      "           -1.6236e+00,  5.8891e-01]]]])\n",
      "torch.Size([2, 3, 64, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.5516, -0.3642, -0.2933,  ...,  0.0848, -1.2803, -0.1713],\n",
       "          [ 0.9577,  0.6101,  0.5850,  ..., -0.9758,  0.4481,  0.5215],\n",
       "          [-0.4869, -0.7056, -0.4157,  ...,  0.2225,  0.5099,  0.3682],\n",
       "          ...,\n",
       "          [-1.1694,  0.7367, -0.5142,  ...,  0.0196,  0.7032, -1.2157],\n",
       "          [-1.0621, -0.6193, -0.5305,  ...,  0.1625,  2.4907, -0.3854],\n",
       "          [ 0.9946,  0.6294,  1.2532,  ...,  1.7814, -1.2138, -0.9374]],\n",
       "\n",
       "         [[-1.8309, -0.3052,  1.2083,  ...,  0.8977,  0.7934, -0.3265],\n",
       "          [ 1.3627, -1.2436, -0.8012,  ...,  0.0849, -0.4284, -0.0883],\n",
       "          [ 1.9049, -0.5306,  0.3147,  ..., -0.5826,  1.0983,  1.4860],\n",
       "          ...,\n",
       "          [-1.5659,  2.0686, -0.0534,  ...,  0.0160, -0.7573, -0.8640],\n",
       "          [-0.1328,  0.2140, -1.2772,  ..., -0.3652,  0.2617,  1.7573],\n",
       "          [-0.5593,  0.6810, -0.3828,  ..., -0.0970, -1.1859, -0.2652]],\n",
       "\n",
       "         [[ 0.6048,  1.4737, -1.7452,  ..., -1.0891, -0.0374,  0.7396],\n",
       "          [ 1.5391,  0.2028,  0.0127,  ...,  0.5471,  0.2285,  0.1754],\n",
       "          [-0.3157, -0.0918, -0.5647,  ...,  1.1901, -0.7629,  0.4325],\n",
       "          ...,\n",
       "          [ 1.7141, -1.2070,  0.4210,  ..., -0.3442,  0.4850,  2.1209],\n",
       "          [-0.2337, -0.1276, -0.4851,  ...,  0.7059,  0.2374, -1.5976],\n",
       "          [-0.1429, -2.2047,  0.3800,  ..., -0.3960,  1.1931, -0.8554]]],\n",
       "\n",
       "\n",
       "        [[[ 0.9446,  0.1417,  0.2201,  ..., -1.3826, -0.3103,  0.9348],\n",
       "          [ 0.1375,  0.2508, -1.2949,  ..., -0.3886, -0.7910, -0.0082],\n",
       "          [-0.0580,  0.3374, -0.8254,  ...,  0.4002,  0.5962, -0.5527],\n",
       "          ...,\n",
       "          [ 1.5394,  1.1426,  1.6787,  ...,  0.5158,  0.0726, -2.0031],\n",
       "          [-1.0778,  0.4670,  0.9579,  ...,  0.1766,  2.1505, -0.2897],\n",
       "          [-0.4798,  0.0699,  1.0871,  ...,  0.0746,  1.8936, -1.5346]],\n",
       "\n",
       "         [[-1.1606,  0.0379, -0.8813,  ..., -1.2096, -0.0395, -0.0089],\n",
       "          [ 0.0376,  1.7136, -0.5303,  ..., -2.0764, -1.4149, -0.1564],\n",
       "          [ 0.7622, -0.3501,  0.1083,  ...,  0.3672, -0.7390,  1.1232],\n",
       "          ...,\n",
       "          [-0.4079,  2.3104, -0.7270,  ...,  0.9453,  1.6630,  0.6795],\n",
       "          [ 1.4943, -0.1821,  0.9393,  ..., -1.1043,  0.6578, -1.0425],\n",
       "          [ 0.0536,  0.6534, -0.9541,  ...,  0.9424, -0.1676,  0.4559]],\n",
       "\n",
       "         [[ 0.3973, -0.0542, -0.1592,  ..., -1.2983, -0.4609,  0.6040],\n",
       "          [ 1.1889, -0.6910,  0.7631,  ..., -0.1399, -0.5460, -0.8007],\n",
       "          [-3.2473,  0.7240, -0.5538,  ...,  0.1360,  0.8785,  1.8971],\n",
       "          ...,\n",
       "          [-1.1435,  0.3933, -0.1804,  ...,  1.7095, -0.1214, -0.4815],\n",
       "          [-1.1940, -0.6916, -0.3856,  ...,  0.9089,  0.4013,  0.1168],\n",
       "          [ 0.2224,  1.8797, -1.4136,  ..., -0.8383, -1.6488,  0.5915]]]],\n",
       "       grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With Learnable Parameters\n",
    "m = nn.BatchNorm2d(num_features=3)\n",
    "# Without Learnable Parameters\n",
    "# m = nn.BatchNorm2d(100, affine=False)\n",
    "input = torch.randn(2, 3, 64, 64)\n",
    "output = m(input)\n",
    "print(input)\n",
    "print(output.size())\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9960)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input[1].detach().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9960)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input[1].detach().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.1565,  0.7500, -0.3719,  ..., -0.9616,  0.4348,  0.4259],\n",
      "          [-0.6004, -0.8510, -0.6980,  ...,  0.2051,  1.4555,  1.2885],\n",
      "          [ 1.4530,  1.5289,  1.0650,  ...,  0.5348,  2.6172, -0.8863],\n",
      "          ...,\n",
      "          [-0.0803, -0.8151,  1.7993,  ...,  0.1407,  1.3291, -0.1148],\n",
      "          [-1.2900,  0.5844,  0.1830,  ...,  0.3862, -0.3855, -0.3404],\n",
      "          [-0.8001, -0.9073,  0.3587,  ...,  0.8436, -0.5880,  0.1786]],\n",
      "\n",
      "         [[-0.7840,  0.8379,  0.7247,  ...,  0.3759,  0.5021,  0.0217],\n",
      "          [ 0.6922, -0.9915,  1.3850,  ...,  0.5162, -0.6761, -0.9231],\n",
      "          [ 1.3833,  0.2084,  2.2427,  ..., -0.7024,  0.5072, -0.1283],\n",
      "          ...,\n",
      "          [-0.0527, -1.6055,  0.2229,  ..., -0.4965,  0.0445, -0.1832],\n",
      "          [-0.2423,  0.7202, -0.8157,  ...,  0.5042,  0.8021, -0.4585],\n",
      "          [ 2.3486, -1.0346, -0.3242,  ...,  1.0822,  1.1736,  0.0142]],\n",
      "\n",
      "         [[-1.4340,  0.3589, -0.4900,  ..., -0.5965,  1.9081,  2.0831],\n",
      "          [ 0.1741,  0.5044,  0.4953,  ..., -0.2874,  1.0790,  0.0516],\n",
      "          [ 1.6999,  0.0167,  0.5804,  ...,  0.2162, -0.6158, -1.8157],\n",
      "          ...,\n",
      "          [ 2.6120, -0.7968, -0.4748,  ..., -1.2285, -1.1479,  2.3184],\n",
      "          [ 1.2569, -0.4784, -1.4767,  ...,  1.6130, -0.9769,  0.8590],\n",
      "          [-1.4686, -1.0462, -0.2538,  ..., -0.9307, -1.0878, -1.3442]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8415,  0.0047,  0.0673,  ...,  0.6285, -0.3504, -0.0398],\n",
      "          [ 0.3891,  1.5215,  0.4459,  ...,  0.2793,  0.3026,  1.6416],\n",
      "          [ 1.2004, -2.0084,  1.4346,  ...,  0.4158, -0.6903, -0.3204],\n",
      "          ...,\n",
      "          [-0.7130,  0.6653, -0.7236,  ...,  1.6591,  1.1978,  0.1330],\n",
      "          [ 0.6800, -0.4143,  0.0636,  ..., -0.6248,  0.8930, -0.1705],\n",
      "          [-0.3336,  1.6140,  0.1306,  ...,  0.2352, -0.4602,  0.0444]],\n",
      "\n",
      "         [[ 0.1259, -0.4905,  0.2405,  ...,  2.2272,  0.5915,  1.2731],\n",
      "          [ 0.7229,  0.7584, -0.2897,  ...,  1.5693,  0.3043,  0.2655],\n",
      "          [-0.9763,  1.7585, -1.4931,  ...,  1.5093, -1.2722, -0.7880],\n",
      "          ...,\n",
      "          [ 0.2642,  0.1264,  0.6189,  ..., -0.1266,  0.3461, -0.0362],\n",
      "          [-0.6259,  0.4844, -0.7984,  ...,  0.1799,  2.3602, -1.1906],\n",
      "          [ 1.7190, -1.0045,  0.2022,  ..., -0.8592,  1.4162,  0.2675]],\n",
      "\n",
      "         [[-1.4677, -1.2856,  0.2618,  ...,  0.0367,  1.2428,  0.3705],\n",
      "          [-0.0819,  1.1415,  0.7658,  ...,  0.6098,  0.4374, -1.4122],\n",
      "          [-0.2694, -1.3015, -0.9450,  ...,  0.1179, -0.6089,  0.5067],\n",
      "          ...,\n",
      "          [ 0.0669,  0.0799,  1.0809,  ..., -0.5802,  0.1992,  1.3120],\n",
      "          [-1.1165, -1.4728,  0.1407,  ...,  1.7942,  1.8295,  0.0704],\n",
      "          [ 0.4379,  0.8998, -0.1978,  ..., -2.1409, -0.1335,  0.3941]]]])\n",
      "torch.Size([2, 3, 64, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.6897e-01,  7.4678e-01, -3.8666e-01,  ..., -9.8237e-01,\n",
       "            4.2833e-01,  4.1941e-01],\n",
       "          [-6.1751e-01, -8.7066e-01, -7.1608e-01,  ...,  1.9631e-01,\n",
       "            1.4595e+00,  1.2908e+00],\n",
       "          [ 1.4570e+00,  1.5337e+00,  1.0650e+00,  ...,  5.2935e-01,\n",
       "            2.6331e+00, -9.0633e-01],\n",
       "          ...,\n",
       "          [-9.2037e-02, -8.3439e-01,  1.8068e+00,  ...,  1.3125e-01,\n",
       "            1.3318e+00, -1.2684e-01],\n",
       "          [-1.3141e+00,  5.7944e-01,  1.7394e-01,  ...,  3.7926e-01,\n",
       "           -4.0040e-01, -3.5475e-01],\n",
       "          [-8.1921e-01, -9.2752e-01,  3.5146e-01,  ...,  8.4137e-01,\n",
       "           -6.0494e-01,  1.6954e-01]],\n",
       "\n",
       "         [[-8.0300e-01,  8.3563e-01,  7.2127e-01,  ...,  3.6889e-01,\n",
       "            4.9637e-01,  1.0979e-02],\n",
       "          [ 6.8844e-01, -1.0126e+00,  1.3882e+00,  ...,  5.1063e-01,\n",
       "           -6.9390e-01, -9.4351e-01],\n",
       "          [ 1.3866e+00,  1.9968e-01,  2.2548e+00,  ..., -7.2052e-01,\n",
       "            5.0145e-01, -1.4049e-01],\n",
       "          ...,\n",
       "          [-6.4176e-02, -1.6329e+00,  2.1427e-01,  ..., -5.1248e-01,\n",
       "            3.4082e-02, -1.9603e-01],\n",
       "          [-2.5566e-01,  7.1665e-01, -8.3502e-01,  ...,  4.9849e-01,\n",
       "            7.9943e-01, -4.7414e-01],\n",
       "          [ 2.3617e+00, -1.0562e+00, -3.3841e-01,  ...,  1.0824e+00,\n",
       "            1.1748e+00,  3.4635e-03]],\n",
       "\n",
       "         [[-1.4596e+00,  3.5170e-01, -5.0590e-01,  ..., -6.1352e-01,\n",
       "            1.9168e+00,  2.0936e+00],\n",
       "          [ 1.6494e-01,  4.9866e-01,  4.8950e-01,  ..., -3.0126e-01,\n",
       "            1.0792e+00,  4.1172e-02],\n",
       "          [ 1.7064e+00,  5.9212e-03,  5.7548e-01,  ...,  2.0754e-01,\n",
       "           -6.3306e-01, -1.8453e+00],\n",
       "          ...,\n",
       "          [ 2.6279e+00, -8.1584e-01, -4.9061e-01,  ..., -1.2520e+00,\n",
       "           -1.1706e+00,  2.3313e+00],\n",
       "          [ 1.2589e+00, -4.9424e-01, -1.5028e+00,  ...,  1.6187e+00,\n",
       "           -9.9786e-01,  8.5691e-01],\n",
       "          [-1.4946e+00, -1.0679e+00, -2.6732e-01,  ..., -9.5117e-01,\n",
       "           -1.1099e+00, -1.3689e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 8.3979e-01,  8.4386e-04,  6.3666e-02,  ...,  6.2622e-01,\n",
       "           -3.5509e-01, -4.3713e-02],\n",
       "          [ 3.8622e-01,  1.5215e+00,  4.4322e-01,  ...,  2.7620e-01,\n",
       "            2.9952e-01,  1.6418e+00],\n",
       "          [ 1.1995e+00, -2.0172e+00,  1.4343e+00,  ...,  4.1301e-01,\n",
       "           -6.9585e-01, -3.2502e-01],\n",
       "          ...,\n",
       "          [-7.1861e-01,  6.6316e-01, -7.2921e-01,  ...,  1.6593e+00,\n",
       "            1.1969e+00,  1.2947e-01],\n",
       "          [ 6.7789e-01, -4.1910e-01,  5.9952e-02,  ..., -6.3017e-01,\n",
       "            8.9135e-01, -1.7475e-01],\n",
       "          [-3.3827e-01,  1.6141e+00,  1.2712e-01,  ...,  2.3195e-01,\n",
       "           -4.6513e-01,  4.0726e-02]],\n",
       "\n",
       "         [[ 1.2243e-01, -4.9556e-01,  2.3725e-01,  ...,  2.2289e+00,\n",
       "            5.8909e-01,  1.2724e+00],\n",
       "          [ 7.2090e-01,  7.5640e-01, -2.9424e-01,  ...,  1.5693e+00,\n",
       "            3.0125e-01,  2.6232e-01],\n",
       "          [-9.8252e-01,  1.7590e+00, -1.5005e+00,  ...,  1.5092e+00,\n",
       "           -1.2791e+00, -7.9374e-01],\n",
       "          ...,\n",
       "          [ 2.6106e-01,  1.2286e-01,  6.1660e-01,  ..., -1.3075e-01,\n",
       "            3.4316e-01, -4.0103e-02],\n",
       "          [-6.3130e-01,  4.8178e-01, -8.0414e-01,  ...,  1.7654e-01,\n",
       "            2.3622e+00, -1.1974e+00],\n",
       "          [ 1.7194e+00, -1.0108e+00,  1.9887e-01,  ..., -8.6516e-01,\n",
       "            1.4158e+00,  2.6430e-01]],\n",
       "\n",
       "         [[-1.4751e+00, -1.2925e+00,  2.5863e-01,  ...,  3.2980e-02,\n",
       "            1.2420e+00,  3.6755e-01],\n",
       "          [-8.5920e-02,  1.1404e+00,  7.6384e-01,  ...,  6.0749e-01,\n",
       "            4.3465e-01, -1.4195e+00],\n",
       "          [-2.7390e-01, -1.3085e+00, -9.5112e-01,  ...,  1.1441e-01,\n",
       "           -6.1421e-01,  5.0410e-01],\n",
       "          ...,\n",
       "          [ 6.3199e-02,  7.6229e-02,  1.0797e+00,  ..., -5.8546e-01,\n",
       "            1.9587e-01,  1.3114e+00],\n",
       "          [-1.1231e+00, -1.4803e+00,  1.3718e-01,  ...,  1.7948e+00,\n",
       "            1.8302e+00,  6.6764e-02],\n",
       "          [ 4.3519e-01,  8.9822e-01, -2.0211e-01,  ..., -2.1499e+00,\n",
       "           -1.3765e-01,  3.9129e-01]]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.LayerNorm(normalized_shape=(64,64))\n",
    "# Without Learnable Parameters\n",
    "m = nn.LayerNorm([3, 64, 64])\n",
    "input = torch.randn(2, 3, 64, 64)\n",
    "output = m(input)\n",
    "print(input)\n",
    "print(output.size())\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 4, 9],\n",
      "        [4, 3, 2, 9]])\n",
      "torch.Size([2, 4, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9467,  0.0607,  1.4769],\n",
       "         [-0.1438,  0.0460, -1.1133],\n",
       "         [ 0.0701,  1.3681,  0.7398],\n",
       "         [-2.1502,  0.6903, -0.1385]],\n",
       "\n",
       "        [[ 0.0701,  1.3681,  0.7398],\n",
       "         [ 0.0580,  0.6396, -1.2366],\n",
       "         [-0.1438,  0.0460, -1.1133],\n",
       "         [-2.1502,  0.6903, -0.1385]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an Embedding module containing 10 tensors of size 3\n",
    "embedding = nn.Embedding(num_embeddings = 10, ## size of the dictionary of embeddings\n",
    "                         embedding_dim=3) ## the size of each embedding vector\n",
    "# a batch of 2 samples of 4 indices each\n",
    "input = torch.LongTensor([[1, 2, 4, 9], [4, 3, 2, 9]])\n",
    "\n",
    "output = embedding(input)\n",
    "print(input)\n",
    "print(output.size())\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.7932,  0.6299],\n",
       "          [ 0.8435,  0.8923]],\n",
       "\n",
       "         [[ 1.2835,  0.6578],\n",
       "          [ 1.8061,  2.2923]],\n",
       "\n",
       "         [[ 0.5800,  1.9448],\n",
       "          [ 0.3711,  0.3666]]],\n",
       "\n",
       "\n",
       "        [[[-0.3181,  0.8630],\n",
       "          [ 1.5073,  0.5394]],\n",
       "\n",
       "         [[ 0.4939,  1.0390],\n",
       "          [ 0.5135,  1.3587]],\n",
       "\n",
       "         [[ 0.5705,  2.5824],\n",
       "          [ 1.3930,  0.9852]]]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.MaxPool2d(kernel_size=(2,2), stride=2, padding=0, dilation=1) # default stride = kernel\n",
    "input = torch.randn(2, 3, 4, 4)\n",
    "output = m(input)\n",
    "print(output.size())\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2, 5, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.4137, 0.4168, 0.6267, 0.5545, 0.1852],\n",
       "          [0.4755, 0.8939, 0.7794, 0.4487, 0.4183],\n",
       "          [0.4353, 0.1060, 0.7417, 0.5332, 0.9933],\n",
       "          [0.5534, 0.8294, 0.9621, 0.3030, 0.6233],\n",
       "          [0.7462, 0.3160, 0.1598, 0.2552, 0.4829]],\n",
       "\n",
       "         [[0.6314, 0.1528, 0.6282, 0.6284, 0.9382],\n",
       "          [0.3003, 0.6618, 0.0927, 0.5614, 0.6508],\n",
       "          [0.9528, 0.7099, 0.8240, 0.6259, 0.2566],\n",
       "          [0.5557, 0.3863, 0.2540, 0.2950, 0.3233],\n",
       "          [0.9933, 0.7359, 0.6636, 0.0043, 0.4087]]],\n",
       "\n",
       "\n",
       "        [[[0.4160, 0.0852, 0.8259, 0.1677, 0.5866],\n",
       "          [0.4327, 0.5851, 0.9825, 0.6645, 0.1688],\n",
       "          [0.5623, 0.6275, 0.6107, 0.7818, 0.8212],\n",
       "          [0.0745, 0.9408, 0.1810, 0.6503, 0.4775],\n",
       "          [0.9192, 0.9951, 0.2679, 0.0293, 0.7661]],\n",
       "\n",
       "         [[0.9098, 0.9990, 0.3957, 0.6331, 0.3246],\n",
       "          [0.2829, 0.2258, 0.0270, 0.9127, 0.0318],\n",
       "          [0.5094, 0.8721, 0.1583, 0.9802, 0.6206],\n",
       "          [0.2394, 0.5353, 0.2095, 0.5855, 0.4009],\n",
       "          [0.3429, 0.6315, 0.3676, 0.1442, 0.8895]]],\n",
       "\n",
       "\n",
       "        [[[0.3835, 0.8773, 0.8932, 0.0261, 0.4029],\n",
       "          [0.0409, 0.8474, 0.1278, 0.6114, 0.1201],\n",
       "          [0.1033, 0.2026, 0.8580, 0.1044, 0.4606],\n",
       "          [0.1543, 0.0077, 0.6379, 0.9617, 0.7075],\n",
       "          [0.5621, 0.5973, 0.7218, 0.8221, 0.8840]],\n",
       "\n",
       "         [[0.0362, 0.1215, 0.0225, 0.8265, 0.8760],\n",
       "          [0.9774, 0.3193, 0.0887, 0.2335, 0.1362],\n",
       "          [0.6791, 0.3128, 0.6300, 0.7843, 0.2589],\n",
       "          [0.7623, 0.0980, 0.2758, 0.2031, 0.2933],\n",
       "          [0.0819, 0.0266, 0.8626, 0.3160, 0.8514]]],\n",
       "\n",
       "\n",
       "        [[[0.3324, 0.6479, 0.3433, 0.7759, 0.5931],\n",
       "          [0.7751, 0.7705, 0.1348, 0.9795, 0.0371],\n",
       "          [0.3834, 0.4036, 0.4608, 0.9026, 0.5727],\n",
       "          [0.4242, 0.0856, 0.4176, 0.2464, 0.7642],\n",
       "          [0.5900, 0.1904, 0.9748, 0.8650, 0.1046]],\n",
       "\n",
       "         [[0.1738, 0.2051, 0.1964, 0.2242, 0.5535],\n",
       "          [0.7571, 0.8902, 0.3837, 0.1060, 0.3427],\n",
       "          [0.6775, 0.4504, 0.3143, 0.6345, 0.8249],\n",
       "          [0.2795, 0.7209, 0.2166, 0.7587, 0.3579],\n",
       "          [0.1717, 0.9039, 0.8834, 0.3023, 0.2624]]],\n",
       "\n",
       "\n",
       "        [[[0.1336, 0.6530, 0.2959, 0.1077, 0.7880],\n",
       "          [0.5737, 0.7712, 0.3006, 0.2227, 0.8520],\n",
       "          [0.8714, 0.1901, 0.1401, 0.4936, 0.8375],\n",
       "          [0.0675, 0.3793, 0.7157, 0.9549, 0.8531],\n",
       "          [0.0603, 0.0605, 0.6753, 0.4881, 0.8861]],\n",
       "\n",
       "         [[0.6507, 0.9753, 0.6817, 0.8591, 0.6728],\n",
       "          [0.4230, 0.2879, 0.3942, 0.3825, 0.7590],\n",
       "          [0.6397, 0.3901, 0.4507, 0.7640, 0.5696],\n",
       "          [0.4245, 0.4384, 0.6438, 0.9424, 0.4656],\n",
       "          [0.8294, 0.6660, 0.7235, 0.6515, 0.5402]]]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Unflatten(1, (2, 5, 5)) \n",
    "input = torch.rand(5, 50)\n",
    "output = m(input)\n",
    "print(output.size())\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1958,  1.0164])\n",
      "tensor([0.2322, 0.7343])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Sigmoid() # 1/(1+ e**(-x))\n",
    "input = torch.randn(2)\n",
    "output = m(input)\n",
    "print(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0791,  0.0007, -0.3884, -0.0749,  0.3717,  0.2087, -0.0190,  0.0519,\n",
       "         -0.0928, -0.2545],\n",
       "        [-0.1441,  0.0767, -0.2908, -0.0611,  0.3775,  0.1745,  0.1058,  0.0007,\n",
       "         -0.2172, -0.2198],\n",
       "        [-0.2000,  0.0842, -0.2380, -0.1137,  0.3960,  0.1900,  0.0168, -0.0478,\n",
       "         -0.2367, -0.2394]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features=28*28, out_features=20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_model(input_image) # logits - raw values in [-infty, infty] \n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0930, 0.1007, 0.0683, 0.0934, 0.1460, 0.1240, 0.0988, 0.1060, 0.0917,\n",
       "         0.0780],\n",
       "        [0.0866, 0.1079, 0.0747, 0.0940, 0.1458, 0.1190, 0.1111, 0.1000, 0.0805,\n",
       "         0.0802],\n",
       "        [0.0833, 0.1107, 0.0802, 0.0908, 0.1512, 0.1230, 0.1035, 0.0970, 0.0803,\n",
       "         0.0801]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)\n",
    "pred_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0246,  0.0040, -0.0346,  ...,  0.0210,  0.0203, -0.0181],\n",
      "        [-0.0066,  0.0261, -0.0342,  ..., -0.0343, -0.0258,  0.0323]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0339,  0.0023], device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0208, -0.0348, -0.0147,  ..., -0.0129,  0.0115, -0.0020],\n",
      "        [ 0.0379,  0.0059,  0.0047,  ..., -0.0382,  0.0369, -0.0121]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([10]) | Values : tensor([0.0437, 0.0024], device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {seq_model}\\n\\n\")\n",
    "\n",
    "for name, param in seq_model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a linearly separable dataset with two classes\n",
    "X, y = make_blobs(n_samples=1000,\n",
    "                  n_features=2, \n",
    "                  centers=2, \n",
    "                  cluster_std=3,\n",
    "                  random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 2), (200, 2), (800,), (200,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=23,\n",
    "                                                    shuffle=True\n",
    "                                                   )\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" \n",
    "    if torch.backends.mps.is_available() \n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\") # MPS is metal performance Shaders (metal GPUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten() # flatten it from any dimension to 1\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            # nn.Linear(512, 512),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0993, 0.1093, 0.0907, 0.1076, 0.0965, 0.0882, 0.0996, 0.1163, 0.1002,\n",
       "         0.0924]], device='mps:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device) # batch of 1\n",
    "\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "pred_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([7], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save and load model using pickle\n",
    "torch.save(model, \"my_model.pickle\")\n",
    "model = torch.load(\"my_model.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## recommended way of saving a model is to leave the model design in code and keep only the weights.\n",
    "\n",
    "torch.save(model.state_dict(), \"my_model_weights.pickle\")\n",
    "model = nn.Sequential(nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            # nn.Linear(512, 512),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(512, 10))\n",
    "model.load_state_dict(torch.load(\"my_model_weights.pickle\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
