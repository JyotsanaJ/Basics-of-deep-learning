{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/jyotsana/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"dataset_2/train.csv\", nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Index   100 non-null    int64 \n",
      " 1   Review  100 non-null    object\n",
      " 2   label   100 non-null    int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 2.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;html&gt;.This is a very short reviewüòÅ üòÖ .\\n\\nThi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Decid√≠ probar Galloping Groomers porque han es...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>This store certainly indulges my out of contro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bugs in my salad and vomit in the bathroom uri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;br&gt;I have a dog walking business and this par...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                             Review  label\n",
       "0      0  <html>.This is a very short reviewüòÅ üòÖ .\\n\\nThi...      1\n",
       "1      1  Decid√≠ probar Galloping Groomers porque han es...      1\n",
       "2      2  This store certainly indulges my out of contro...      1\n",
       "3      3  Bugs in my salad and vomit in the bathroom uri...      0\n",
       "4      4  <br>I have a dog walking business and this par...      1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    53\n",
       "1    47\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_htmltags(df):\n",
    "  df['Review'] = df['Review'].str.replace(r'<[^<>]*>', '', regex=True)\n",
    "  return df\n",
    "\n",
    "data = remove_htmltags(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = \"!\"#$%&'()*+, -/:;<=>?@[\\]^_`{|}~\"\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    return text.translate(str.maketrans(\"\",\"\", punctuations))\n",
    "\n",
    "data[\"Review\"] = data[\"Review\"].apply(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace(r'^\\s*$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index     False\n",
       "Review    False\n",
       "label     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Review', 'label']].to_csv(\"dataset_2/cleaned_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"csv\", data_files=\"dataset_2/cleaned_train.csv\", split=\"train\", nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "# from datasets import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = data.train_test_split(test_size=0.2, shuffle=True)\n",
    "dataset[\"train\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=16\n",
    "MAX_LENGTH=512\n",
    "OUT_DIR=\"analysis\"\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def custom_collate_fn(examples):\n",
    "    inputs = [f\"Sentiment Analysis: {article}\" for article in examples['Review']]\n",
    "    # model_inputs = tokenizer(\n",
    "    #     inputs,\n",
    "    #     max_length=MAX_LENGTH,\n",
    "    #     truncation=True,\n",
    "    #     padding='max_length'\n",
    "    # )\n",
    "    \n",
    "    # print(model_inputs)\n",
    "    labels= torch.tensor(examples[\"label\"], dtype=float.long)\n",
    "\n",
    "    return {\n",
    "        \"tokenized_input\": inputs,\n",
    "        \"label\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(data, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)\n",
    "# len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Review': [\".This is a very short reviewüòÅ üòÖ .\\\\n\\\\nThis place served me the best meal I've had in years, and I'm enormously happy it's open; it's spendy, but damn, if you're going out for a good dinner, this is the place I'd recommend, hands down.\\\\n\\\\nPhenomenal.  Perfect.  No fault..  Awesomeüòí \",\n",
       "  'Decid√≠ probar Galloping Groomers porque han estado en el negocio durante mucho tiempo y deben ser buenosüòá . Bueno, estaba extremadamente decepcionado y no solo le dieron a mi Bichon quemaduras de navaja en su vientre, sino que el corte no fue uniforme. se ve√≠a terrible'],\n",
       " 'label': tensor([1, 1])}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=OUT_DIR,\n",
    "\n",
    "    num_train_epochs=EPOCHS,\n",
    "    max_steps = -1, # if set will overwrite epochs\n",
    "    dataloader_num_workers=2,\n",
    "\n",
    "    ###### Memory optimization\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=1,\n",
    "    gradient_checkpointing = False,\n",
    "    bf16=False, # Needs Ampere\n",
    "    fp16=False,\n",
    "    # deepspeed=False,\n",
    "    # fsdp=False,\n",
    "    dataloader_pin_memory = True,\n",
    "\n",
    "    ###### Better training\n",
    "    lr_scheduler_type=\"linear\", # check SchedulerType\n",
    "    warmup_steps = 200,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=0.001,\n",
    "    eval_steps=200,\n",
    "    evaluation_strategy='epoch',\n",
    "\n",
    "    # logging_dir=OUT_DIR,\n",
    "    save_strategy='epoch',\n",
    "    logging_steps=200,\n",
    "    save_total_limit=1,\n",
    "    # report_to='tensorboard',\n",
    "    save_safetensors=True, # To save state_dicts instead of whole,\n",
    "    # save_only_model= False,\n",
    "\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model= \"loss\",\n",
    "    greater_is_better=False,\n",
    "    resume_from_checkpoint = False,\n",
    "    use_cpu = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_valid,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002c5b99990a441b8ab151bbbf311874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = load_dataset(\"csv\",data_files=\"dataset_2/test.csv\", nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(df):\n",
    "    inputs=[f\"Sentiment Analysis: {article}\" for article in df['Review']]\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=True,\n",
    "        padding='max_length'\n",
    "    )\n",
    "    output = model.generate(model_inputs)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.metrics.f1_score(label,pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
