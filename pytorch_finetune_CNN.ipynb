{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x13f7b7e50>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seed\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "# train_dataset = train_dataset.data[:100]\n",
    "# test_dataset = test_dataset.data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 28, 28]), torch.Size([10000, 28, 28]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data.shape, test_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7500"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 8\n",
    "num_epochs = 5\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True) \n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False) \n",
    "\n",
    "len(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        # Linear function\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        # Non-linearity\n",
    "        self.relu = nn.ReLU()\n",
    "        # Linear function (readout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Linear function\n",
    "        out = self.fc1(x)\n",
    "        # Non-linearity\n",
    "        out = self.relu(out)\n",
    "        # Linear function (readout)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 28*28\n",
    "hidden_dim = 100\n",
    "output_dim = 10\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedforwardNeuralNetModel(\n",
       "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step_size: at how many multiples of epoch you decay\n",
    "# step_size = 1, after every 1 epoch, new_lr = lr * gamma \n",
    "# step_size = 2, after every 2 epoch, new_lr = lr * gamma \n",
    "\n",
    "# gamma = decaying factor\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (images, labels) in enumerate(train_loader):\n",
    "    # print(images.view(-1, 28*28).shape)\n",
    "    images = images.view(-1, 28*28).requires_grad_() # torch.Size(1,784)\n",
    "\n",
    "    # Clear gradients w.r.t. parameters\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass to get output/logits\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 10])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 LR: [0.1]\n",
      "Iteration: 500. Loss: 0.20129147171974182. Accuracy: 0.6754999756813049\n",
      "Iteration: 1000. Loss: 0.041485805064439774. Accuracy: 0.6621000170707703\n",
      "Iteration: 1500. Loss: 0.25040629506111145. Accuracy: 0.5716000199317932\n",
      "Iteration: 2000. Loss: 0.195490762591362. Accuracy: 0.5327000021934509\n",
      "Iteration: 2500. Loss: 0.133193239569664. Accuracy: 0.6402999758720398\n",
      "Iteration: 3000. Loss: 0.169741690158844. Accuracy: 0.6416000127792358\n",
      "Iteration: 3500. Loss: 0.22962498664855957. Accuracy: 0.5105000138282776\n",
      "Iteration: 4000. Loss: 0.04928706958889961. Accuracy: 0.628600001335144\n",
      "Iteration: 4500. Loss: 0.10088468343019485. Accuracy: 0.5314000248908997\n",
      "Iteration: 5000. Loss: 0.14670239388942719. Accuracy: 0.5123999714851379\n",
      "Iteration: 5500. Loss: 0.223624587059021. Accuracy: 0.5368000268936157\n",
      "Iteration: 6000. Loss: 0.19441582262516022. Accuracy: 0.40860000252723694\n",
      "Iteration: 6500. Loss: 0.17741283774375916. Accuracy: 0.4999000132083893\n",
      "Iteration: 7000. Loss: 0.24769264459609985. Accuracy: 0.5410000085830688\n",
      "Iteration: 7500. Loss: 0.22104822099208832. Accuracy: 0.5152000188827515\n",
      "Epoch: 1 LR: [0.0010000000000000002]\n",
      "Iteration: 8000. Loss: 0.08639615774154663. Accuracy: 0.6223000288009644\n",
      "Iteration: 8500. Loss: 0.10800249874591827. Accuracy: 0.6646000146865845\n",
      "Iteration: 9000. Loss: 0.16603486239910126. Accuracy: 0.6883000135421753\n",
      "Iteration: 9500. Loss: 0.04494386538863182. Accuracy: 0.6654999852180481\n",
      "Iteration: 10000. Loss: 0.052193533629179. Accuracy: 0.7084000110626221\n",
      "Iteration: 10500. Loss: 0.01599501632153988. Accuracy: 0.7563999891281128\n",
      "Iteration: 11000. Loss: 0.059137191623449326. Accuracy: 0.7426999807357788\n",
      "Iteration: 11500. Loss: 0.09021703898906708. Accuracy: 0.766700029373169\n",
      "Iteration: 12000. Loss: 0.06351616233587265. Accuracy: 0.7824000120162964\n",
      "Iteration: 12500. Loss: 0.04890647158026695. Accuracy: 0.767300009727478\n",
      "Iteration: 13000. Loss: 0.06754124164581299. Accuracy: 0.8104000091552734\n",
      "Iteration: 13500. Loss: 0.07125347852706909. Accuracy: 0.7896000146865845\n",
      "Iteration: 14000. Loss: 0.051869649440050125. Accuracy: 0.7610999941825867\n",
      "Iteration: 14500. Loss: 0.09151308238506317. Accuracy: 0.7980999946594238\n",
      "Iteration: 15000. Loss: 0.205336332321167. Accuracy: 0.7976999878883362\n",
      "Epoch: 2 LR: [0.00010000000000000003]\n",
      "Iteration: 15500. Loss: 0.036176010966300964. Accuracy: 0.8274999856948853\n",
      "Iteration: 16000. Loss: 0.03520149737596512. Accuracy: 0.8270000219345093\n",
      "Iteration: 16500. Loss: 0.18555308878421783. Accuracy: 0.8334000110626221\n",
      "Iteration: 17000. Loss: 0.06388422846794128. Accuracy: 0.8323000073432922\n",
      "Iteration: 17500. Loss: 0.03835761547088623. Accuracy: 0.8327999711036682\n",
      "Iteration: 18000. Loss: 0.06265290826559067. Accuracy: 0.8360999822616577\n",
      "Iteration: 18500. Loss: 0.1360439956188202. Accuracy: 0.8363000154495239\n",
      "Iteration: 19000. Loss: 0.03668597713112831. Accuracy: 0.8353000283241272\n",
      "Iteration: 19500. Loss: 0.06915364414453506. Accuracy: 0.836899995803833\n",
      "Iteration: 20000. Loss: 0.007293326780200005. Accuracy: 0.8349000215530396\n",
      "Iteration: 20500. Loss: 0.05876407399773598. Accuracy: 0.8406999707221985\n",
      "Iteration: 21000. Loss: 0.06744756549596786. Accuracy: 0.8391000032424927\n",
      "Iteration: 21500. Loss: 0.046240806579589844. Accuracy: 0.8409000039100647\n",
      "Iteration: 22000. Loss: 0.08164811879396439. Accuracy: 0.84170001745224\n",
      "Iteration: 22500. Loss: 0.3041441738605499. Accuracy: 0.8402000069618225\n",
      "Epoch: 3 LR: [1.0000000000000004e-05]\n",
      "Iteration: 23000. Loss: 0.043548475950956345. Accuracy: 0.8413000106811523\n",
      "Iteration: 23500. Loss: 0.2115374654531479. Accuracy: 0.8417999744415283\n",
      "Iteration: 24000. Loss: 0.00017869485600385815. Accuracy: 0.8411999940872192\n",
      "Iteration: 24500. Loss: 0.07319933921098709. Accuracy: 0.8414000272750854\n",
      "Iteration: 25000. Loss: 0.07397083193063736. Accuracy: 0.8422999978065491\n",
      "Iteration: 25500. Loss: 0.19124695658683777. Accuracy: 0.8420000076293945\n",
      "Iteration: 26000. Loss: 0.07971347123384476. Accuracy: 0.842199981212616\n",
      "Iteration: 26500. Loss: 0.025701725855469704. Accuracy: 0.8420000076293945\n",
      "Iteration: 27000. Loss: 0.010774222202599049. Accuracy: 0.8424999713897705\n",
      "Iteration: 27500. Loss: 0.044569969177246094. Accuracy: 0.8424999713897705\n",
      "Iteration: 28000. Loss: 0.06288808584213257. Accuracy: 0.8421000242233276\n",
      "Iteration: 28500. Loss: 0.07674995064735413. Accuracy: 0.8396000266075134\n",
      "Iteration: 29000. Loss: 0.007731049321591854. Accuracy: 0.8417999744415283\n",
      "Iteration: 29500. Loss: 0.02622199058532715. Accuracy: 0.8420000076293945\n",
      "Iteration: 30000. Loss: 0.01267479732632637. Accuracy: 0.8424999713897705\n",
      "Epoch: 4 LR: [1.0000000000000004e-06]\n",
      "Iteration: 30500. Loss: 0.025064244866371155. Accuracy: 0.8424000144004822\n",
      "Iteration: 31000. Loss: 0.060239966958761215. Accuracy: 0.8425999879837036\n",
      "Iteration: 31500. Loss: 0.0928068608045578. Accuracy: 0.842199981212616\n",
      "Iteration: 32000. Loss: 0.016052469611167908. Accuracy: 0.8422999978065491\n",
      "Iteration: 32500. Loss: 0.017409225925803185. Accuracy: 0.8424000144004822\n",
      "Iteration: 33000. Loss: 0.06579504162073135. Accuracy: 0.8428000211715698\n",
      "Iteration: 33500. Loss: 0.09583742171525955. Accuracy: 0.8424999713897705\n",
      "Iteration: 34000. Loss: 0.12441705167293549. Accuracy: 0.8422999978065491\n",
      "Iteration: 34500. Loss: 0.03149500489234924. Accuracy: 0.8422999978065491\n",
      "Iteration: 35000. Loss: 0.05722486227750778. Accuracy: 0.8427000045776367\n",
      "Iteration: 35500. Loss: 0.05944175273180008. Accuracy: 0.8425999879837036\n",
      "Iteration: 36000. Loss: 0.12210550159215927. Accuracy: 0.8427000045776367\n",
      "Iteration: 36500. Loss: 0.02188834920525551. Accuracy: 0.8428000211715698\n",
      "Iteration: 37000. Loss: 0.038737643510103226. Accuracy: 0.8428999781608582\n",
      "Iteration: 37500. Loss: 0.2618492841720581. Accuracy: 0.8427000045776367\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    # Print Learning Rate\n",
    "    print('Epoch:', epoch,'LR:', scheduler.get_lr())\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images\n",
    "        images = images.view(-1, 28*28).requires_grad_() # torch.Size(2,784)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) # logits, dimension 10\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images to a Torch Variable\n",
    "                images = images.view(-1, 28*28)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = correct / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item()/8, accuracy))\n",
    "        \n",
    "    # Decay Learning Rate\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
