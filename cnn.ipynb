{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disadvantages of Convolutional Neural Networks (CNNs):\n",
    "* Computationally expensive to train and require a lot of memory.\n",
    "* Can be prone to overfitting if not enough data or proper regularization is used.\n",
    "* Requires large amounts of labeled data.\n",
    "* Interpretability is limited, itâ€™s hard to understand what the network has learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different CNN arcitectures\n",
    "\n",
    "1. LeNet (1998) - 6 Level conv n/w\n",
    "2. AlexNet (2012)\n",
    "3. ZFNet (2013)\n",
    "4. GoogleNet/Inception (2014)\n",
    "5. VGGNet (2014)\n",
    "6. Resnet (2015)\n",
    "7. DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    " \n",
    "# Load the digits dataset\n",
    "digits = load_digits()\n",
    "X, y = digits.images, digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 8, 8, 1), (1797, 10))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "# Normalizing pixel values\n",
    "X = X / 16.0\n",
    " \n",
    "# Reshaping the data to fit the model\n",
    "# CNN in Keras requires an extra dimension at the end for channels,\n",
    "# and the digits images are grayscale so it's just 1 channel\n",
    "X = X.reshape(-1, 8, 8, 1)\n",
    "\n",
    "# Convert labels to categorical (one-hot encoding)\n",
    "y = to_categorical(y)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1437, 8, 8, 1), (1437, 10), (360, 8, 8, 1))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a simple CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(8, 8, 1))) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))  # 10 classes for digits 0-9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 2.2882 - accuracy: 0.1754 - val_loss: 2.2559 - val_accuracy: 0.5639\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 2.1970 - accuracy: 0.4558 - val_loss: 2.0875 - val_accuracy: 0.5639\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 1.9250 - accuracy: 0.6360 - val_loss: 1.6985 - val_accuracy: 0.7667\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 1.4813 - accuracy: 0.7404 - val_loss: 1.2349 - val_accuracy: 0.8000\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 1.0932 - accuracy: 0.8107 - val_loss: 0.9108 - val_accuracy: 0.8750\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.8425 - accuracy: 0.8198 - val_loss: 0.7263 - val_accuracy: 0.8528\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.6965 - accuracy: 0.8323 - val_loss: 0.6048 - val_accuracy: 0.8778\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.5918 - accuracy: 0.8601 - val_loss: 0.5240 - val_accuracy: 0.8778\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.5269 - accuracy: 0.8664 - val_loss: 0.4671 - val_accuracy: 0.8889\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.8824 - val_loss: 0.4210 - val_accuracy: 0.8889\n",
      "12/12 [==============================] - 0s 404us/step - loss: 0.4210 - accuracy: 0.8889\n"
     ]
    }
   ],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    " \n",
    "# Training the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)\n",
    " \n",
    "# Evaluate the model\n",
    "accuracy = model.evaluate(X_test, y_test)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8526012"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(X_test)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):   \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            nn.Conv2d(1, 4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining another 2D convolution layer\n",
    "            nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(4 * 7 * 7, 10)\n",
    "        )\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the model\n",
    "model = Net()\n",
    "# defining the optimizer\n",
    "optimizer = nn.Adam(model.parameters(), lr=0.07)\n",
    "# defining the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the number of epochs\n",
    "n_epochs = 25\n",
    "# empty list to store training losses\n",
    "train_losses = []\n",
    "# empty list to store validation losses\n",
    "val_losses = []\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    # getting the training set\n",
    "    x_train, y_train = nn.Variable(train_x), nn.Variable(train_y)\n",
    "    # getting the validation set\n",
    "    x_val, y_val = nn.Variable(val_x), nn.Variable(val_y)\n",
    "    # converting the data into GPU format\n",
    "    if torch.cuda.is_available():\n",
    "        x_train = x_train.cuda()\n",
    "        y_train = y_train.cuda()\n",
    "        x_val = x_val.cuda()\n",
    "        y_val = y_val.cuda()\n",
    "\n",
    "    # clearing the Gradients of the model parameters\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # prediction for training and validation set\n",
    "    output_train = model(x_train)\n",
    "    output_val = model(x_val)\n",
    "\n",
    "    # computing the training and validation loss\n",
    "    loss_train = criterion(output_train, y_train)\n",
    "    loss_val = criterion(output_val, y_val)\n",
    "    train_losses.append(loss_train)\n",
    "    val_losses.append(loss_val)\n",
    "\n",
    "    # computing the updated weights of all the model parameters\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    tr_loss = loss_train.item()\n",
    "    if epoch%2 == 0:\n",
    "        # printing the validation loss\n",
    "        print('Epoch : ',epoch+1, '\\t', 'loss :', loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# training the model\n",
    "for epoch in range(n_epochs):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plotting the training and validation loss\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prediction for training set\n",
    "with torch.no_grad():\n",
    "    output = model(train_x.cuda())\n",
    "    \n",
    "softmax = torch.exp(output).cpu()\n",
    "prob = list(softmax.numpy())\n",
    "predictions = np.argmax(prob, axis=1)\n",
    "\n",
    "# accuracy on training set\n",
    "accuracy_score(train_y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG Architecture (Visual Geometric group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is very slow to train (the original VGG model was trained on Nvidia Titan GPU for 2â€“3 weeks).\n",
    "* The size of VGG-16 trained imageNet weights is 528 MB. So, it takes quite a lot of disk space and bandwidth which makes it inefficient.\n",
    "* 138 million parameters lead to exploding gradients problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet\n",
    "\n",
    "* solve the problem of the vanishing/exploding gradient,\n",
    "* The skip connection connects activations of a  layer to further layers by skipping some layers in between. \n",
    "* advantage of adding this type of skip connection is that if any layer hurt the performance of architecture then it will be skipped by regularization.\n",
    "* Pool added only at the start and end of the Resnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet\n",
    "\n",
    "* the output of each layer is connected to the input of every subsequent layers to help with vanishing or exploding gradient . \n",
    "* All convolutions in a dense block are ReLU-activated and use batch normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
